{
  "name": "Micro-Expression Recognition using Histogram-Based Feature Descriptors",
  "tagline": "Satyam Dhar and Kevin Zhang",
  "body": "### Abstract\r\nHuman facial expressions contain substantial information about how a person is feeling at any instant. People can fake their facial expressions but micro-expressions, which are short, involuntary facial expressions, can reveal a person’s underlying emotions even when the person is trying to conceal their feelings. In this project, we build a system for automatic facial expression recognition (FER) and later extend this system for micro-expression recognition (MER). For FER, we evaluate and compare performance of two different feature descriptors, LBP and LPQ. For MER, we examine the performance of LBP-TOP for MER and evaluate the performance of the LPQ-TOP feature descriptor which has not been applied to this problem in the past. Our results show that LPQ performs slightly better than LBP for both facial expression recognition and micro-expression recognition in our experiments on the Cohn Kanade and CASME II datasets.\r\n\r\n### Databases Used\r\nFor our facial expression recognition system, we used the extended Cohn-Kanade (CK+) database, , one of the most popular and comprehensive facial-expression image databases. All image sequences show subject’s faces in full frontal view with little horizontal or vertical rotation.\r\n\r\nWe chose the CASME II database because it supports for our MER experiments. All sequences in the dataset were captured with 200 fps camera and all samples have a large face size of about 280 pixels by 340 pixels. In addition, the researchers elicited spontaneous micro-expressions from participants by asking them to suppress their facial expressions while viewing emotional videos. The researchers simulated a high-stakes situation by forcing participants to take a long and boring survey if they were caught displaying a facial expression. The ground truth in the database was established by two facial action coders who independently labeled each image sequence into one of five labels: happiness, disgust, surprise, repression, and others.\r\n\r\n### Project Report\r\nYou can download the complete project report from [here](https://docs.google.com/document/d/155CW1NYJzpW-nL4LDYB_cSPupitFthkPbmVChMZI14M/edit?usp=sharing).\r\n\r\n### Authors and Contributors\r\nSatyam Dhar (@sdhar1) and Kevin Zhang (@kztheavatar) worked on this research as a part of their final project for CS766 - Computer Vision course at UW-Madison during the Spring 2016 semester. They would like to thank Professor Mohit Gupta for his continued guidance and support.\r\n\r\n### Support or Contact\r\nPlease reach out to Satyam Dhar (sdhar@cs.wisc.edu) or Kevin Zhang (kzhang@cs.wisc.edu) if you have any comments or questions.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}